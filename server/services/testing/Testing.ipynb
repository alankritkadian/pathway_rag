{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.environ['OPENAI_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_finance_bench.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df['question'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = df['answer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore', module=\"langsmith.client\")\n",
    "from modular_agent import create_agent\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from finance.corporate_finance import *\n",
    "from finance.financial_markets import *\n",
    "from finance.personal_finance import *\n",
    "from finance.finance_group import finance_group_tool\n",
    "from maths.code_executor import *\n",
    "from report_gen.report_gen import reportgen_tool\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain import hub\n",
    "from new_adaptive_rag import data_node_tool\n",
    "from Bad_queries import QueryValidator\n",
    "from response_transformation import ResponseTransformer\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "config = RunnableConfig(recursion_limit=60)\n",
    "\n",
    "joiner_prompt = hub.pull(\"yankee/llm-compiler-joiner\").partial(examples='')\n",
    "finance_prompt = hub.pull('yankee/llm-compiler-finance')\n",
    "joiner_prompt_finance = hub.pull('yankee/llm-compiler-joiner').partial(examples='')\n",
    "supervisor_prompt = hub.pull('llm-compiler/planner')\n",
    "maths_prompt = hub.pull('llm-compiler/planner-maths-testing')\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "llm_mini = ChatOpenAI(model='gpt-4o-mini')\n",
    "finance_tools = [\n",
    "    finance_group_tool\n",
    "]\n",
    "maths_tools = [code_tool]\n",
    "\n",
    "\n",
    "\n",
    "finance_chain = create_agent(llm_mini, finance_tools,finance_prompt,joiner_prompt_finance,'finance')\n",
    "maths_chain = create_agent(llm, maths_tools,supervisor_prompt,joiner_prompt,'maths')\n",
    "\n",
    "def maths_tool_node(query, context):\n",
    "    response = maths_chain.invoke({\"messages\": [HumanMessage(content=f\"For the following query, {query} and the following {context}, perform the actions\")]})\n",
    "    return response\n",
    "\n",
    "def finance_tool_node(query, context):\n",
    "    response = finance_chain.invoke({\"messages\": [HumanMessage(content=f\"For the following query, {query} and the following {context}, perform the actions\")]})\n",
    "    return response\n",
    "\n",
    "class MathsToolNode(BaseModel):\n",
    "    query: str = Field(description=\"The mathematical query/operation to be executed\")\n",
    "    context: str = Field(description=\"The context to be considered while executing the query\")\n",
    "\n",
    "class FinanceToolNode(BaseModel):\n",
    "    query: str = Field(description=\"The financial query/operation to be executed\")\n",
    "    context: str = Field(description=\"The context to be considered while executing the query\")\n",
    "\n",
    "maths_tool_agent = StructuredTool.from_function(\n",
    "    maths_tool_node,\n",
    "    name='maths_tool_agent',\n",
    "    description='''maths_tool_agent(query: str, context[Optional]: str) -> str:\n",
    "    An LLM agent with access to mathematical tools and a code executor to perform basic arithmetic operations and more.\n",
    "    Use it whenever you need to perform mathematical operations or need to generate and run some custom code or need to analyze some data. The node can generate its own code, so you need to only provide the query and context.\n",
    "    Context Specific Rules:\n",
    "    The context is optional and can be used to provide additional information or constraints for the query.\n",
    "    If the context is provided, the agent will use it to perform the actions specified in the query.\n",
    "    If you do not provide a context, the agent will perform the actions based on the query alone.\n",
    "    Example usage:\n",
    "    maths_tool_agent(\"Compare the GDP of India, America and Russia over five years\", \"GDP of India for 2015-2020 = [21,22,24,25,30] GDP of America for 2015-2020 = [30,32,34,35,40] GDP of Russia for 2015-2020 = [15,16,18,20,22]\"),\n",
    "    returns: \"The GDP of India has increased by 9.52 over the last five years.\n",
    "              The GDP of America has increased by 10.00 over the last five years.\n",
    "              The GDP of Russia has increased by 46.67 over the last five years.\"\n",
    "    \n",
    "    maths_tool_agent(\"Calculate the average of the following numbers: [1,2,3,4,5]\",\"\")\n",
    "    returns: \"The average of the numbers [1, 2, 3, 4, 5] is 3.0.\",\n",
    "    ''',\n",
    "    args_schema=MathsToolNode,\n",
    ")\n",
    "\n",
    "finance_tool_agent = StructuredTool.from_function(\n",
    "    finance_tool_node,\n",
    "    name='finance_tool_agent',\n",
    "    description='''finance_tool_agent(query: str, context[Optional]: str) -> str:\n",
    "    npv_tool,financial_analysis_tool,payback_period_tool,irr_tool,break_even_tool,\n",
    "    depreciation_tool,working_capital_tool,stock_price_change_tool,moving_average_tool,\n",
    "    bollinger_bands_tool,\n",
    "    volatility_tool,\n",
    "    exponential_moving_average_tool,\n",
    "    rsi_tool,\n",
    "    monthly_savings_tool,\n",
    "    loan_emi_tool,\n",
    "    retirement_savings_tool,\n",
    "    emergency_fund_tool,\n",
    "    debt_to_income_ratio_tool,\n",
    "    investment_growth_tool\n",
    "    Example usage:\n",
    "    finance_tool_agent(\"Calculate the NPV of a project with the following cash flows: [100,200,300,400,500]\",\"Initial investment = 1000, Discount rate = 10%\"),\n",
    "    returns: \"The Net Present Value (NPV) of the project is 139.75.\"\n",
    "    \n",
    "    finance_tool_agent(\"Calculate the moving average of the stock prices: [100,110,200,500,600] over a period of 5 days.\",\"\"),\n",
    "    returns: \"The moving average of the stock prices over a period of 5 days is 302.0.\"\n",
    "    ''',\n",
    "    args_schema = FinanceToolNode\n",
    ")\n",
    "\n",
    "tools = [maths_tool_agent,finance_group_tool,data_node_tool,reportgen_tool]\n",
    "\n",
    "supervisor = create_agent(llm, tools, supervisor_prompt, joiner_prompt,'supervisor')\n",
    "\n",
    "class StateCompression(TypedDict):\n",
    "    summary: str = Field(description=\"A summary of the state, including all the function calls and their results, and any conclusions if drawn\")\n",
    "\n",
    "system_compressor = \"\"\"You are an expert at compressing the state of the system. \n",
    "You have been given the task to compress the state of the system into a summary. \n",
    "You must include all the function calls and their results, and any conclusions if drawn.\n",
    "You must provide this summary in a structured format as per the Act model. \"\"\"\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_compressor),\n",
    "        (\"human\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def restart(messages,response):\n",
    "    # query = state['user_question']\n",
    "    # response = input(f'Enter the response for the query-> {query}:\\nAnswer: ')\n",
    "    messages.append(HumanMessage(content=response))\n",
    "    structured_llm_compressor = llm_mini.with_structured_output(StateCompression)\n",
    "    state_compressor = route_prompt | structured_llm_compressor\n",
    "    summary = state_compressor.invoke({\"messages\": messages})\n",
    "    print('Summary:',summary)\n",
    "    # state[\"messages\"].append(HumanMessage(content=summary[\"summary\"]))\n",
    "    return summary[\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Infer(query,mode):\n",
    "    # query = \"What is the GDP of India and USA. What is the difference between two. What is the precentage increase in their GDPs\"\n",
    "    for step in supervisor.stream({'messages': [HumanMessage(content=query)],'hitl_flag':False},stream_mode='values'):\n",
    "        print('============================================STEP START========================================================')\n",
    "        last_state = step\n",
    "        # print('Last State:',last_state.__dict__)\n",
    "        # print('Last State:',type(last_state))\n",
    "        print(\"Last Message: \",step[\"messages\"][-1].content)\n",
    "        print('=============================================STEP END=======================================================')\n",
    "\n",
    "\n",
    "    hitl_flag = last_state[\"hitl_flag\"]\n",
    "    print(hitl_flag)\n",
    "    if hitl_flag:\n",
    "        if mode == 'hitl':\n",
    "            messages = last_state['messages']\n",
    "            user_question = last_state[\"user_question\"]\n",
    "            print('User Question:',user_question)\n",
    "            response = input(f'Enter the response for the query {user_question}:')\n",
    "            summary = restart(messages,response)\n",
    "            new_state = {'messages':[HumanMessage(content=summary)]}\n",
    "            response = supervisor.invoke(new_state)[\"messages\"][-1].content\n",
    "        else:\n",
    "            response = \"Sorry I am not able to help you with this query. Please try again later.\"\n",
    "    else:\n",
    "        response = last_state[\"messages\"][-1].content\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hitl = []\n",
    "results_non_hitl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_bench(questions,index):\n",
    "    print('========== Running Test Bench ==========')\n",
    "    # print('========== Testing for HITL Mode ==========')\n",
    "    num = len(questions) + index\n",
    "    for i,query in enumerate(questions):\n",
    "        print(f'Running Test {i+1}/{num}')\n",
    "        print('Query:',query)\n",
    "        response = Infer(query,mode='hitl')\n",
    "        results_hitl.append((i,response))\n",
    "        print('Response:',response)\n",
    "    print('========== Testing for Non-HITL Mode ==========')\n",
    "    for i,query in enumerate(questions):\n",
    "        print(f'Running Test {i+index}/{num}')\n",
    "        print('Query:',query)\n",
    "        response = Infer(query,mode='non_hitl')\n",
    "        results_non_hitl.append((i,response))\n",
    "        print('Response:',response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_non_hitl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test_bench(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Evaluation Using LLM as a Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
